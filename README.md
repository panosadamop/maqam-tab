# Ù…Ù‚Ø§Ù…TAB â€” MaqamTAB

> **Microtonal tablature editor** for oud (Ø¹ÙˆØ¯) and saz with AI-powered auto-transcription, maqam detection, and MusicXML export.

Built with **React + Material UI v5** frontend and **FastAPI** backend.

## Features

| Feature | Description |
|---------|-------------|
| ğŸ¤– AI Auto-Transcription | YouTube URL â†’ TAB via Whisper + YIN pitch detection |
| ğŸ™ Live Recording | Real-time microphone recording + analysis |
| âœï¸ TAB Editor | Interactive SVG editor with ornaments & microtones |
| ğŸµ Maqam Analysis | 10 maqam profiles with seyir-aware detection |
| ğŸ“„ Export | MusicXML, ASCII TAB, JSON |
| ğŸ¨ Material UI | Full MUI v5 dark theme with Arabic/Persian fonts |

## Quick Start

### Frontend
```bash
cd frontend
npm install
npm run dev
# â†’ http://localhost:3000
```

### Backend
```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload --port 8000
```

### AI Tools (optional, for AI transcription)
```bash
# macOS
brew install ffmpeg yt-dlp
pip install openai-whisper

# Ubuntu/Debian
sudo apt install ffmpeg
pip install yt-dlp openai-whisper
```

### Docker (full stack)
```bash
docker-compose up
```

## AI Transcription Pipeline

```
YouTube URL / MP3 Upload
    â†“ yt-dlp download
    â†“ ffmpeg â†’ 16kHz mono WAV
    â†“ Onset Detection (RMS + adaptive threshold)
    â†“ YIN Pitch Detection (60â€“1800 Hz)
    â†“ Tempo Estimation + Rhythm Quantization
    â†“ Maqam Detection (10 profiles, seyir-aware)
    â†“ Whisper AI (optional metadata)
    â†’ Notes in TAB Editor
```

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Backend health + AI tool status |
| GET | `/api/ai/status` | AI tools availability |
| POST | `/api/ai/youtube` | Start YouTube transcription job |
| POST | `/api/ai/upload` | Upload audio file for transcription |
| GET | `/api/ai/job/{id}` | Poll job status |
| DELETE | `/api/ai/job/{id}` | Cancel job |
| POST | `/api/export/pdf` | PDF export via LilyPond |

## Environment Variables

```bash
export WHISPER_MODEL=base  # tiny | base | small | medium | large
```

## Tech Stack

- **Frontend**: React 18, Material UI v5, Vite
- **Backend**: FastAPI, Python 3.11+
- **AI**: OpenAI Whisper, YIN pitch detection
- **Audio**: Web Audio API, yt-dlp, ffmpeg
